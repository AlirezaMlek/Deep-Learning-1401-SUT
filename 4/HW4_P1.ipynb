{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n--RzfV08tjJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras import callbacks\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding, GRU\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.utils import Sequence, to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwTi8TIl8xYN"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxjpsOYu85vs",
        "outputId": "ac0bc4b2-9738-4fb5-ecfe-cf72d28b2b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hpjYFmIxHZeTQt4VHovfQGAJ9oLY8xbm\n",
            "To: /content/ferdousi.txt\n",
            "100% 4.54M/4.54M [00:00<00:00, 136MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id  1hpjYFmIxHZeTQt4VHovfQGAJ9oLY8xbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5zGDZN6VNZI"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentences):\n",
        "  # Create tokenizer\n",
        "  text_tokenizer = Tokenizer()\n",
        "  # Fit texts\n",
        "  text_tokenizer.fit_on_texts(sentences)\n",
        "  return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmLyez1jVBFp"
      },
      "outputs": [],
      "source": [
        "with open(\"ferdousi.txt\") as f:\n",
        "  raw_data = f.read().splitlines()[2:]\n",
        "f.close()\n",
        "\n",
        "pairs = []\n",
        "for i in range(len(raw_data)):\n",
        "  if i % 2 ==0:\n",
        "    tmp = raw_data[i].split(' ')\n",
        "  else:\n",
        "    tmp.append(' ')\n",
        "    for w in raw_data[i].split(' '):\n",
        "      tmp.append(w)\n",
        "    pairs.append(tmp)\n",
        "\n",
        "text_tokenized, text_tokenizer = tokenize(pairs)\n",
        "\n",
        "max_len = len(max(text_tokenized,key=len))\n",
        "vocab = len(text_tokenizer.word_index) + 1\n",
        "data_size = len(pairs)\n",
        "\n",
        "pad_sentence = pad_sequences(text_tokenized, max_len, padding = \"post\")\n",
        "\n",
        "pad_sentence_cyc = np.concatenate((pad_sentence[1:], pad_sentence[:1]))\n",
        "\n",
        "\n",
        "\n",
        "pad_sentence = pad_sentence.reshape(*pad_sentence.shape, 1)\n",
        "pad_sentence_cyc = pad_sentence_cyc.reshape(*pad_sentence_cyc.shape, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxP2Yb-wAVN9"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input(shape=(max_len,))\n",
        "embedding = Embedding(input_dim=vocab, output_dim=256,)(input_sequence)\n",
        "encoder = LSTM(256, return_sequences=True)(embedding)\n",
        "encoder2 = LSTM(128, return_sequences=True)(encoder)\n",
        "encoder3 = LSTM(128, return_sequences=False)(encoder2)\n",
        "r_vec = RepeatVector(max_len)(encoder3)\n",
        "decoder = LSTM(512, return_sequences=True, dropout=0.2)(r_vec)\n",
        "logits = TimeDistributed(Dense(512, activation = 'relu'))(decoder)\n",
        "logits = TimeDistributed(Dense(vocab))(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qghYvEj4YxuV",
        "outputId": "22ca16bd-c9a0-4707-a771-3fa0fb58d0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 21)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 21, 256)           4611328   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 21, 256)           525312    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 21, 128)           197120    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 21, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 21, 512)           1312768   \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 21, 512)          262656    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 21, 18013)        9240669   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 21, 18013)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,281,437\n",
            "Trainable params: 16,281,437\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "enc_dec_model = Model(input_sequence, Activation('softmax')(logits))\n",
        "enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "enc_dec_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT27aB-iZP45"
      },
      "outputs": [],
      "source": [
        "# Stop training when a monitored metric has stopped improving.\n",
        "earlyStop = callbacks.EarlyStopping( patience=4, verbose=1, restore_best_weights=True, min_delta=1e-4)\n",
        "\n",
        "model_results = enc_dec_model.fit(pad_sentence, pad_sentence_cyc, shuffle=True,\n",
        "                                  batch_size=30, epochs=20, validation_split=.25, callbacks = [earlyStop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKhuRRROZEkH"
      },
      "outputs": [],
      "source": [
        "def logits_to_sentence(indices, tokenizer):\n",
        "\n",
        "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<empty>' \n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in indices])\n",
        "\n",
        "\n",
        "def get_sentence(predict, tokenizer):\n",
        "  output = []\n",
        "  for i in range(predict.shape[1]):\n",
        "    tmp_index =[]\n",
        "    tmp_val = []\n",
        "    for j in range(predict.shape[2]):\n",
        "      if predict[0][i][j]>.001:\n",
        "        tmp_index.append(i)\n",
        "        tmp_val.append(predict[0][i][j])\n",
        "    \n",
        "    tmp_out = np.random.choice(tmp_index, p = tmp_val / sum(tmp_val))\n",
        "    output.append(tmp_out)\n",
        "\n",
        "  return logits_to_sentence(output, tokenizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvdBEA3pZV2i",
        "outputId": "8c99df21-b377-46ed-f244-fa57d6040333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 98ms/step\n",
            "LSTM result:\n",
            "\n",
            "input:\n",
            "به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد\n",
            "predict:\n",
            "<empty>   و به که ز از بر را چو با همی گفت شد شاه تو بود او یکی همه آن\n"
          ]
        }
      ],
      "source": [
        "a=enc_dec_model.predict(pad_sentence[:1][:,:,0])\n",
        "\n",
        "print(\"LSTM result:\\n\")\n",
        "\n",
        "print(\"input:\")\n",
        "print(raw_data[0], raw_data[1])\n",
        "\n",
        "print('predict:')\n",
        "print(get_sentence(a, text_tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTenqGBILVeR"
      },
      "source": [
        "As we can see, only the most frequent words have shown up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmLn0uNrLeEA"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input(shape=(max_len,))\n",
        "embedding = Embedding(input_dim=vocab, output_dim=256,)(input_sequence)\n",
        "encoder = GRU(256, return_sequences=True)(embedding)\n",
        "encoder2 = GRU(128, return_sequences=True)(encoder)\n",
        "encoder3 = GRU(128, return_sequences=False)(encoder2)\n",
        "r_vec = RepeatVector(max_len)(encoder3)\n",
        "decoder1 = GRU(512, return_sequences=True, dropout=0.2)(r_vec)\n",
        "decoder = GRU(256, return_sequences=True, dropout=0.2)(decoder1)\n",
        "logits = TimeDistributed(Dense(512, activation = 'relu'))(decoder)\n",
        "logits = TimeDistributed(Dense(vocab))(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdM7mnEzLyZx",
        "outputId": "464a61a8-7175-4125-db96-46c4fbce027d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 21)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 21, 256)           4611328   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 21, 256)           394752    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 21, 128)           148224    \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 128)               99072     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 21, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 21, 512)           986112    \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 21, 256)           591360    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 21, 512)          131584    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 21, 18013)        9240669   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 21, 18013)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,203,101\n",
            "Trainable params: 16,203,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "enc_dec_model_GRU = Model(input_sequence, Activation('softmax')(logits))\n",
        "enc_dec_model_GRU.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "enc_dec_model_GRU.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKUDtkRHL3z3",
        "outputId": "3bf89afe-9b74-4006-feed-ad4ebcb4d5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1241/1241 [==============================] - 62s 41ms/step - loss: 4.3310 - accuracy: 0.4462 - val_loss: 4.1695 - val_accuracy: 0.4658\n",
            "Epoch 2/20\n",
            "1241/1241 [==============================] - 50s 40ms/step - loss: 3.9767 - accuracy: 0.4631 - val_loss: 4.1079 - val_accuracy: 0.4714\n",
            "Epoch 3/20\n",
            "1241/1241 [==============================] - 50s 40ms/step - loss: 3.9414 - accuracy: 0.4634 - val_loss: 4.1183 - val_accuracy: 0.4717\n",
            "Epoch 4/20\n",
            "1241/1241 [==============================] - 50s 40ms/step - loss: 3.9158 - accuracy: 0.4639 - val_loss: 4.1265 - val_accuracy: 0.4714\n",
            "Epoch 5/20\n",
            "1241/1241 [==============================] - 50s 40ms/step - loss: 3.8971 - accuracy: 0.4641 - val_loss: 4.1484 - val_accuracy: 0.4703\n",
            "Epoch 6/20\n",
            "1241/1241 [==============================] - ETA: 0s - loss: 3.8835 - accuracy: 0.4646Restoring model weights from the end of the best epoch: 2.\n",
            "1241/1241 [==============================] - 50s 40ms/step - loss: 3.8835 - accuracy: 0.4646 - val_loss: 4.1591 - val_accuracy: 0.4709\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "model_results_GRU = enc_dec_model_GRU.fit(pad_sentence, pad_sentence_cyc, shuffle=True,\n",
        "                                  batch_size=30, epochs=20, validation_split=.25, callbacks = [earlyStop])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = enc_dec_model_GRU.predict(pad_sentence[:1][:,:,0])\n",
        "\n",
        "print(\"GRU result:\\n\")\n",
        "\n",
        "print(\"input:\")\n",
        "print(raw_data[0], raw_data[1])\n",
        "\n",
        "print('predict:')\n",
        "print(get_sentence(a, text_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC8YxjoHkbCQ",
        "outputId": "165ce817-5acc-4987-d18c-2851dba7ef79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "GRU result:\n",
            "\n",
            "input:\n",
            "به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد\n",
            "predict:\n",
            "<empty>   و به که ز از بر را چو با همی گفت شد شاه تو بود او یکی همه آن\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}